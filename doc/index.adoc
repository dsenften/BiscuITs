= BiscuITs
Author: Daniel Senften
:email: daniel.senften@ffhs.ch
:doctype: book
include::locale/attributes-de.adoc[]
:imagesdir: images/
:toc: left
:sectnums:
:sectnumlevels: 2
:pdf-theme: themes/pdf-theme.yml
:title-logo-image: image:logo.png[top=0%, align=left, width=20%]
:quick-uri: https://docs.asciidoctor.org/asciidoc/latest/syntax-quick-reference/

[.preamble]
--
[.text-center]
*Abstract*

Dieser Abschnitt muss noch erstellt werden.
--

= Dokumentation: KI-gestützte Microservice-Architektur

== Überblick

Die Anwendung besteht aus folgenden Komponenten:

- *Streamlit UI*: Dient zur Eingabe von Name und Adresse des Anwenders
- *Microservice 1*: Empfängt die Adresse von der UI, ruft die GPT-3 API auf und sendet das Ergebnis an Microservice 2
- *RabbitMQ*: Message Bus zur asynchronen Kommunikation zwischen den Microservices
- *Microservice 2*: Empfängt das Ergebnis von Microservice 1 und sendet es zurück an die UI
- *GPT-3 API*: Wird von Microservice 1 aufgerufen, um Informationen zum angegebenen Ort abzufragen

== Ablauf

1. Der Anwender gibt in der Streamlit UI seinen Namen und seine Adresse (PLZ, Ort) ein.
2. Die UI sendet die Adresse an Microservice 1.
3. Microservice 1 stellt die Adresse in eine Queue von RabbitMQ.
4. Microservice 1 entnimmt die Adresse aus der Queue und ruft damit die GPT-3 API auf. Der Prompt lautet: "Was kannst du mir zu {Ort} sagen?"
5. Die API-Antwort wird von Microservice 1 in eine Ergebnis-Queue von RabbitMQ gestellt.
6. Microservice 2 entnimmt das Ergebnis aus der Queue.
7. Microservice 2 sendet das Ergebnis an die UI zurück.
8. Die UI zeigt das Ergebnis an, sobald es verfügbar ist. Bis dahin wird ein Lade-Spinner angezeigt.

== Komponenten

=== Streamlit UI

Die Benutzeroberfläche ist mit Streamlit implementiert. Sie stellt ein Formular zur Eingabe von Name und Adresse bereit. Beim Absenden des Formulars wird die Adresse an Microservice 1 gesendet. Die UI wartet dann auf die asynchrone Antwort von Microservice 2. Während der Wartezeit wird eine Sanduhr-Animation angezeigt.

=== Microservice 1

Microservice 1 ist in Python implementiert. Er verbindet sich mit RabbitMQ, um Adressen aus einer Queue zu empfangen. Für jede Adresse ruft er die GPT-3 API mit dem Prompt "Was kannst du mir zu {Ort} sagen?" auf. Die Antwort der API stellt er in eine Ergebnis-Queue von RabbitMQ.

=== RabbitMQ

RabbitMQ dient als Message Bus für die asynchrone Kommunikation zwischen den Microservices. Es werden zwei Queues verwendet:

- `address_queue`: Enthält die vom Anwender eingegebenen Adressen
- `result_queue`: Enthält die Ergebnisse der GPT-3 API-Aufrufe

=== Microservice 2

Microservice 2 ist ebenfalls in Python implementiert. Er verbindet sich mit RabbitMQ, um Ergebnisse aus der `result_queue` zu empfangen. Die empfangenen Ergebnisse sendet er an die Streamlit UI zurück.

=== GPT-3 API

Die GPT-3 API von OpenAI wird verwendet, um basierend auf dem angegebenen Ort relevante Informationen abzufragen. Microservice 1 ruft die API mit dem Prompt "Was kannst du mir zu {Ort} sagen?" auf, wobei {Ort} durch den vom Anwender angegebenen Ort ersetzt wird.

== Deployment

Alle Komponenten werden mit Docker containerisiert. Die Container werden mit Docker Compose orchestriert. Die Konfiguration befindet sich in der Datei `docker-compose.yml`. Zum Starten der Anwendung muss lediglich der Befehl `docker compose up` ausgeführt werden.
